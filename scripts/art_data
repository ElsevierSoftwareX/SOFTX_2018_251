#!/usr/bin/env python
import os, json, pickle
import numpy as np
import time
import random
import multiprocessing as mp
import argparse
from event_selector import filter_events_all_tests_stage_1,filter_events_all_tests_stage_2
from calculator.event_energy_calculator import *
from calculator.strain_calculator import strain_calculator_run_all_tests_mp
from calculator.voronoi_structural_analysis import run_all_tests_voronoi_calculator, run_all_tests_voronoi_classifier
from visualizer.strain_visualizer import events_strain_visualization,strain_events_stats_visualization
from correlation_model.correlation_model import residual_threshold_finder, all_events_local_atoms_finder, events_local_atoms
from util import run_tests_triggered_atom_is_max_disp
#from lammps.run import run_lammps
from ART_wrapper.run import run_art_mp, set_up_input_files

def print_input_help():
	"""
	this function print the help to set up input file in a json format
	"""
	print \
	"""
	art_data --settings need an input file in json format specifies the
	following keys:
	
	  path_to_data_dir: str
		path to the art data directory
	  
	  list_of_test_id: list
		list of the tests to be filtered
	  
	  path_to_input_files: str
		path to ART input files, get by os.environ['ART_INPUT']
	
	  total_energy: float
		total potential energy of the ART sample (calculated by lammps)
	  
	  sample_name: str
		file name of the sample configuration file containing atomic coordinates
	  
	  sample_type: str
		sample_type can be either 'dump' or 'lammps_data'
	  
	  box_dim: list,
		the orthogonal box dimension along x, y, z, can be found in
		each ART data directory 1st configuration in the test, e.g.min1000
		
	  identical_event_criteria: dict
	   {"D_init_fin": 0.1, "E_init_fin": 0.005, "E_init_sad": 0.01}
	  
	  re_calc: boolean
		True or False
	  
	  cut_off: cut_off distance for different atom type pair
		eg. {str((1,1)):3.7,str((1,2)):3.7,str((2,2)):3.7}
		means atom type 1 and type 1 cut off distance is 3.7 A
		
	  num_of_proc" number of processors used to run jobs
	    default, max number of cores, mp.cpu_count()
	  
	  re_calc: whether to re-do the calculation and overide,
		default False
	  
	  atom_list: None or local
		if None, calculate all atoms in the configuration
		if local, calculate the local atoms
		e.g. [1,2,3,4,5]
	
	  # for the outlier detection
	  model: sklearn machine learning model used to do outlier detection
		default "LinearSVR"
	  
	  feature: features used as input
		default "displacement"
	  
	  target: targeted properties as model output
		default "shear_strain"
	  
	  residual_threshold: list of relative residual threshold candidates to determine the best residual threshold
	    default, np.arange(0.01, 1.0, 0.01).tolist()
	  
	  final_residual_threshold: float, relative residual threshold used to determine the local atoms index
	   default, 0.54
	
	  # for voronoi analysis
	  voro_cut_off: float, cut_off to determine the nearest neighbors in voronoi analysis
	  a single value, should be max of the cut-off for different atom types, 3.7
	  
	  
	  box_range: the simulation box range in x,y ,z direction
	    e.g. [l_range, l_range, l_range], where l_range = [0.299875, 32.130125]
	    can be found from each ART data directory, e.g. 1st configuration in the test, e.g.min1000
	  
	  periodic: list of perioidic condition in x,y,z
	    for 3D periodic boundary condition, using [True, True, True]
	"""

def print_desc_help():
	"""
	this function print the description about how to use art_data command line
	workflow
	"""
	print \
	"""
	This art_data command line tool are expected to perform the following tasks:
	running lammps and ART simulations to generate sample for ART and ART data of the sample,
	post-processing of ART data in a user workflow in parallel.	
	
	If only a subsection of the MD sample are interested (e.g. grain boundary atoms), it is suggested 
	that only these subsection atoms are output as the configuration sample file.
	
	It is suggested to run a few set of ART data with different paramters to 
	ensure post-filtering activation energy distribution indeed converge by a
	statistical test, such as the t test implemented by --ttest. This ttest argument 
	will need two path arguments that point to two data directories to ensure that
	the average of activation energy and relaxation energy indeed converges.
	
	The post-processing of ART_data needs an input file to set up the settings to run the following tasks.
	The number of processors that will be used will be specified preferaly
	in the input file, if this information does not exists, it will use
	the setting by the command line argument -np
	
	For test whose test_id = 1, the test directory naming test1 or 1 in each ART data 
	directory will be searched.
	
	To run the following tasks, an input file to set up SETTINGS are needed
	
	'art_data -s SETTINGS' (where SETTINGS is the input file name or full path to input file name)
	
	Example 'art_data' JSON input files can be output by the
	  'art_data --example' options:
		
		art_data --example > input.json
	Then the user can edit the parameters in the file as needed and 
	see 'art_data --settings-format' for help.
	
	running ART:
	art_data -s SETTINGS --art --run will take the input parameters in SETTINGS
	such as path_to_input_files, total_energy, box_dim, sample_name, sample_type
	to automatically set up the input files for running art and running ./mod_bart.sh
	inside each run_dir. 
	
	The name of each run_dir is determined by whether there is 
	a file inside path_to_data_dir called central_atom_list.json. 
	This file will be generated when running art_data --example ...
	
	If this file exists, it will load the list inside the file and use each integer element (central_atom id)
	as the name of each run_dir to create each run_dir. If this file does not exists,
	it will load all atoms id in lammps dump or lammps data file and save them as a list
	in a file called central_atom_list.json inside path_to_data_dir.
	
	Then ART input files will be modified corresponding to each central_atom id and copied into each run_dir.
	
	running ./mod_bart.sh will be then done in parallel with the number of processors specified
	in the input settings file
	
	
	1) filter events and perform activation and relaxation energy convergence tests:
	
	  Before this operation, the user should have a few set of ART data
	  available for checking the rough convergence of filtered events and
	  check the convergence of activation energy and relaxation energy by ttest.
	  The ART data can be generated by two arguments --art --run option with different input file parameters.
	  
	  'art_data -s SETTINGS --filter' 
	  will perform the task on path_to_data_dir:
	  it will invoke event_selector.filter_events_all_tests_stage_1 and filter_events_all_tests_stage_2
	  in and filter events based on the three criteria implemented
	  with -p or --path option, it will filter events in the path specified
	  
	  'art_data -s SETTINGS --eng --calc' will invoke
	  event_energy_calculator.energy_calculator_run_all_tests_mp to calculate
	  the activation energy and relaxation energy for all filtered events in
	  path_to_data_dir. With -p or --path option, it will calculate eng 
	  in filter events in the path specified
	  
	  'art_data -s SETTINGS --eng --ttest OPTION PATH_1 PATH_2' will invoke
	  event_energy_calculator.eng_convergence_ttest_ind if OPTION is ind 
	  or event_energy_calculator.eng_convergence_ttest_rel if OPTION is rel
	  , where PATH_1 is the path string to the ART data directory 1 and PATH_2
	  is the path string to the ART data directory 2.	 
	  
	 2) run calculations:
	 
	 "art_data -s SETTINGS --strain --calc" will invoke the strain and displacement calculations for
	 all filtered events and automatically plots results for individual event and statistics
	 for all events, implemented in calculator.strain_calculator.strain_calculator_run_all_tests_mp
	 With -p or --path option, it will calculate strain in the data dir specified
	 
	 "art_data -s SETTINGS --strain -v" will plot the event level quantities after strain calculation
	 "art_data -s input.json --strain --stats" will plot the statists of all events after strain calculation
	 
	 3) determine the local atoms in a STZs for each event by a relative
	 residual threshold
	 
	 art_data -s SETTINGS --find_residual will invoke the 
	 correlation_model.correlation_model.residual_threshold_finder
	 With -p or --path option, it will find residual in the data dir specified
	 
	 current implemented criteria is to plot the relation between
	 the average number of local atoms of all filtered events vs the user
	 chosen relative residual threshold. when it reach convergence as defined by
	 the double slope criteria, it stops.
	 
	 This will determine a reasonable relative residual threshold, e.g. 
	 0.54 for all events
	 
	 4) obtain the local atom index for all individual events
	 
	 art_data -s SETTINGS --find_local_index rel_residual_threshold, where
	 rel_residual_threshold is the relative residual threshold to find 
	 the local atoms. 
	 With -p or --path option, it will find local atom indexes in the data 
	 dir specified.
	 
	 Use the found relative residual threshold to get all local atoms indexes 
	 for all filtered events by correlation_model.correlation_model.all_events_local_atoms_finder

	 5) run local calculations:
	 art_data -s SETTINGS --local --strain --calc will invoke the strain and displacement
	 calculations for local atoms
	 
	 It will rerun calculator.strain_calculator.strain_calculator_run_all_tests_mp 
	 with atom_list = 'local',
	 which will read all local atom indexs saved in local_atoms_index.json
	 
	 art_data -s SETTINGS --local --voro --calc will invoke
	 calculator.voronoi_structural_analysis.run_all_tests_voronoi_calculator
	 with atom_list ='local' when --local is invoked, 
	 it will read local_atoms_index.json and calculate local atoms voronoi index 
	 If local_atoms_index.json not exists, it will calculate all atoms voronoi index
	 
	 art_data -s SETTINGS --voro --classify will
	 Run voronoi_structural_analysis.run_all_tests_voronoi_classifier 
	 to classify and plot the results in voronoi_index_results.json of each event, 
	 and calculate and plot the dynamic transition correlation matrix
	 
	 art_data -s SETTINGS --events_local_atoms will
	 calculate and plot the statistics of number of local atoms and slope for all filtered events 
	 in interested tests list_of_test_id
	 
	 art_data -s SETTINGS --central_atom_max_disp will
	 check if the triggered atom is the max displacement atom in all 
	 filtered events in list_of_test_id
	 
	 6) further correlation analysis between local structure and local properties
	 input file
	  
	"""
def example_input(n_atoms, n_tests):
	"""
	this function returns an example input file json/dict
	"""
	input = dict()
	input["path_to_data_dir"] = os.environ['DATA_DIR']
	if not os.path.isdir(os.environ['DATA_DIR']):
		print "creating directory: %s"%input["path_to_data_dir"]
		os.makedirs(input["path_to_data_dir"])
	
	input["path_to_input_files"] = os.environ['ART_INPUT']
	if n_atoms >= n_tests:
		random.seed(0)
		central_atom_list = random.sample([x+1 for x in xrange(n_atoms)],n_tests)
	else:
		central_atom_list = [x+1 for x in xrange(n_atoms)]
	path_to_central_atom_list = os.path.join(input["path_to_data_dir"],'central_atom_list.json')
	
	with open(path_to_central_atom_list, 'w+') as f:
		json.dump(central_atom_list,f)
	
	# create all tests for each atom in central_atoms_list
	# select part tests for further post-processing in list_of_test_id
	# default using all tests, which are created by central_atom_list
	# usually user are interested in a single test post-processing results
	# then they can manually edit the input file
	input["list_of_test_id"] = central_atom_list
	size = 32.130125 - 0.299875
	input['box_dim'] = [size, size, size]
	input['total_energy'] = -46021.0583322591
	input['sample_name'] = "dump_10E11"
	input['sample_type'] = "dump"
	input['cut_off'] = {str((1,1)):3.7,str((1,2)):3.7,str((2,2)):3.7}
	input['identical_event_criteria'] = {"D_init_fin": 0.1, "E_init_fin": 0.005, "E_init_sad": 0.01}
	input['num_of_proc'] = mp.cpu_count()
	input['re_calc'] = False
	input['atom_list'] = None
	
	# for the outlier detection
	input['model'] = "LinearSVR"
	input['feature'] = "displacement"
	input['target'] =  "shear_strain"
	input['residual_threshold'] = np.arange(0.01, 1.0, 0.01).tolist()
	#input['final_residual_threshold'] = 0.54
	
	# for voronoi analysis
	input['voro_cut_off'] = 3.7
	l_range = [0.299875, 32.130125]
	input['box_range'] = [l_range, l_range, l_range]
	input['periodic'] = [True, True, True]
	
	return input
	
	
if __name__ == "__main__":

  parser = argparse.ArgumentParser(description = 'begin art data processing')
  
  # add command line arguments, order does not matter
  parser.add_argument('--desc', help='Print extended usage description', action="store_true")
  parser.add_argument('--settings-format', help='Print input file description', action="store_true")
  # when --example argument is missing in command line, the default created by store_true is False
  parser.add_argument('--example', nargs=2, help='Print example input file, need two input integer arguments',type=int, metavar=('n_atoms in sample', 'num central_atom tests to be created'))
  
  
  parser.add_argument('-s', '--settings', nargs=1, help='Settings input filename, where SETTINGS is the input file name', type=str)
  
  parser.add_argument('--filter', help='filter events to remove unsuccessful and redudant event', action="store_true")  
  
  parser.add_argument('--eng', help='perform operations on activation and relaxation energy', action="store_true")
  parser.add_argument('--strain', help='perform operations on atomic strain and displacement', action="store_true")
  parser.add_argument('--voro', help='perform operations on voronoi cell analysis', action="store_true")
  
  parser.add_argument('-c','--calc', help='perform calculations', action="store_true")
  parser.add_argument('-v', help='plot results', action="store_true")
  parser.add_argument('--ttest_kfold', nargs=3, metavar=('OPTION', 'k', 'n'), help='perform t test on random k folds by n times on a single data')
  parser.add_argument('--stats', help='plot results statistics', action="store_true")
  parser.add_argument('--ttest', nargs=3, metavar=('OPTION', 'PATH_1', 'PATH_2'), help='perform t test to check convergence, need three arguments OPTION, PATH_1, PATH_2, OPTION is either ind or rel, PATH_1 is the path string to data dir 1, PATH_2 is the path string to data dir 2')
  parser.add_argument('--classify', help='classify the results', action="store_true")
  
  
  parser.add_argument('--find_residual', help='find the relative residual threshold for outlier detection in atomic displacement vs strain for all events in specified tests', action = "store_true")
  parser.add_argument('--find_local_index', nargs=1,metavar=('rel_residual_threshold'), type=float, help='find the local atom index in all events in specified tests, where rel_residual_threshold is the user specified relative threshold residual')
  parser.add_argument('--local', help='invoke calculations on local atoms that are determined by --find_local_index', action="store_true")
  parser.add_argument('--events_local_atoms', help='calculate the average local atoms and their statistics in all filtered events in specified tests', action = "store_true")
  parser.add_argument('--central_atom_max_disp', help='check if the central atom is the maximum displacement atom for all filtered events in specified tests', action = "store_true")
  
  #parser.add_argument('--strain_calc', help='perform atomic strain and displacement calculations', action="store_true")
  #parser.add_argument('--strain_v', help='perform atomic strain and displacement calculations', action="store_true")
  
  parser.add_argument('-p', '--path', nargs=1, help='Set up path to data directory, overrides the path in user specified input file', type=str)
  parser.add_argument('-np', nargs=1, help='set up number of processors to run the jobs, default 1 without specifying, will be overided by user specified input file', type=int, default=1)
  parser.add_argument('--re_calc', help='redo the calculations by setting the re_calc argument, will override the re_calc argument in user specified input file', action="store_true")
  
  
  # check the default attribute name of dest
  parser.add_argument('-q','--quiet', help='Quiet output', action="store_true", default=False)
  
  # to be implemented in the future
  # integration with running art
  parser.add_argument('--art', help='setting up ART input files, and running art in parallel with np specified in SETTINGS file', action='store_true')
  
  # integration with lammps
  parser.add_argument('--lammps',help='begin lammps mode for generating initial ART samples, to be implemented',action="store_true")
  
  parser.add_argument('--run', help='begin running simulations after --lammps or --art mode', action="store_true")
  
  #parser.add_argument('-v','--verbose', help='verbose output', action="store_true", default=False)
  
  
  args = parser.parse_args()
  
  args.verbose = not args.quiet
  
  if args.settings_format:
	print_input_help()
	exit()
  
  if args.example:
	#print jsonpickle.encode(example_input())
	print json.dumps(example_input(args.example[0],args.example[1]), indent=2)
	#print example_input()
	exit()
  if args.path:
	path_to_data_dir = args.path[0]
  
  if args.lammps and args.art:
	  raise Exception("can only run one simulation at a time")
  if args.lammps:
	  if args.run:
		  run_lammps(args.run[0])
		  exit()
  
  
		  
  if args.settings:
	if args.verbose:
		print "Loading", args.settings[0]
	#input_param = jsonpickle.decode(open(args.settings[0],'r').read())
	#input_param = json.loads(open(args.settings[0], 'r').read())
	input_param = json.load(open(args.settings[0], 'r'))
	
	new_cut_off_dict = dict()
	for k,v in input_param['cut_off'].items():
		new_cut_off_dict[eval(k)] = v
	input_param['cut_off'] = new_cut_off_dict
	
	if 'num_of_proc' not in input_param:
		if args.np <= mp.cpu_count():
			input_param['num_of_proc'] = args.np
		else:
			raise Exception("number of cores specified by -np must be no greater than %s"%mp.cpu_count())
	if (not args.path) and ("path_to_data_dir" in input_param):
		path_to_data_dir = input_param["path_to_data_dir"]
	
	if "re_calc" not in input_param:
		input_param["re_calc"] = False
	if args.re_calc:
		input_param["re_calc"] = True
	
	if args.art:
		if args.run:
		  print "being setting up the ART input files!"
		  set_up_input_files(path_to_data_dir, input_param)
		  print "starting running art in parallel"
		  run_art_mp(path_to_data_dir, input_param)
		  #run_art_mp(args.run[0])
		  exit()

	if args.filter:
		#if args.path:
		#	path_to_data_dir = args.path[0]
		print "current data dir:", path_to_data_dir
		print "begining filter events in stage I two criteria"
		filter_events_all_tests_stage_1(path_to_data_dir, input_param)
		print "begining filter events in stage II 1 criteria"
		filter_events_all_tests_stage_2(path_to_data_dir, input_param)
		exit()
	
	if args.eng:
		print "begin operation on activation and relaxation energy,--path argument overides path_to_data_dir in input file"
		#if args.path:
		#	path_to_data_dir = args.path[0]
		if args.calc:
			print "beging calculating activation and relaxation energy distribution for all filtered events in input file list_of_test_id of %s"%path_to_data_dir
			energy_calculator_run_all_tests_mp(path_to_data_dir, input_param)
			exit()
		if args.ttest_kfold:
			print "being performing t test"
			print "t test mode is", args.ttest_kfold[0]
			print "random %s fold number"%args.ttest_kfold[1]
			print "split data into k fold into %s times"%args.ttest_kfold[2]
			is_converged = eng_k_fold_ttest(path_to_data_dir, int(args.ttest_kfold[1]), args.ttest_kfold[0], int(args.ttest_kfold[2]))
			if is_converged == True:
				print "activation and relaxation energy converged"
			else:
				print "activation and relaxation energy did NOT converged!"
			exit()
			
		if args.ttest:
			print "being performing t test"
			print "t test mode is", args.ttest[0]
			print "path to ART data dir 1:", args.ttest[1]
			print "path to ART data dir 2:", args.ttest[2]
			if args.ttest[0] == 'ind':
				# ttest_ind has equal_var = False option, default True
				is_converged = eng_convergence_ttest_ind(args.ttest[1], args.ttest[2])
			elif args.ttest[0] == 'rel':
				is_converged = eng_convergence_ttest_rel(args.ttest[1], args.ttest[2])
			if is_converged == True:
				print "activation and relaxation energy converged"
			else:
				print "activation and relaxation energy did NOT converged!"
			exit()	
	
	if args.strain:
		if args.local:
			input_param["atom_list"] = "local"
		if (args.calc and args.v) or (args.calc and args.stats) or (args.stats and args.v):
			raise Exception("operations on strain can not be more than 1 at one time")
		if args.calc:
			# strain calculation is invoked
			start_time = time.time()
			strain_calculator_run_all_tests_mp(path_to_data_dir, input_param)
			print "total run time:", time.time() - start_time, "seconds"
			exit()
		elif args.v:
			events_strain_visualization(path_to_data_dir, input_param)
			exit()
		elif args.stats:
			strain_events_stats_visualization(path_to_data_dir, input_param)
			exit()
	
	if args.find_residual:
		print "start finding relative residual threshold for outlier detection"
		residual_threshold_finder(path_to_data_dir, input_param)
		exit()
	
	if args.find_local_index:
		# if --find_local_index was set a default =0.54, then args.find_local_index is a float, not a list
		residual_threshold = args.find_local_index[0]
		all_events_local_atoms_finder(path_to_data_dir, input_param, residual_threshold)
		exit()
	
	if args.events_local_atoms:		
		events_local_atoms(path_to_data_dir, input_param)
		exit()
		
	if args.central_atom_max_disp:
		run_tests_triggered_atom_is_max_disp(path_to_data_dir, input_param)
		exit()
	
	if args.voro:
		if args.local:
			input_param["atom_list"] = "local"
		if args.calc:
			input_param['cut_off'] = input_param['voro_cut_off']
			start_time = time.time()
			run_all_tests_voronoi_calculator(path_to_data_dir,input_param)
			print "total run time:", time.time() - start_time, "seconds"
			exit()
		elif args.classify:
			start_time = time.time()
			run_all_tests_voronoi_classifier(path_to_data_dir,input_param)
			print "total run time:", time.time() - start_time, "seconds"
			exit()
				
  elif args.desc:
	print_desc_help()
  else:
	parser.print_help()
